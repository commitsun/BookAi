import asyncio
import logging
from dotenv import load_dotenv
from core.graph import app   # ğŸ‘ˆ importamos desde core/graph

# =========
# ConfiguraciÃ³n
# =========
load_dotenv()

# Configurar logs de conversaciÃ³n con encoding seguro
logging.basicConfig(
    filename="chat_history.log",
    level=logging.INFO,
    format="%(asctime)s - %(message)s",
    encoding="utf-8",  # ğŸ‘ˆ aseguramos UTF-8
)

async def chat():
    print("ğŸ’¬ Chat HotelAI (escribe 'salir' para terminar)\n")

    # Estado inicial con memoria vacÃ­a
    state = {
        "messages": [],
        "route": None,
        "rationale": None,
        "language": None,
        "summary": None
    }

    while True:
        try:
            user_msg = input("TÃº: ")
        except EOFError:
            break

        if user_msg.lower() in ["salir", "exit", "quit"]:
            print("ğŸ‘‹ Â¡Hasta pronto!")
            break

        # Guardamos mensaje del usuario en memoria
        state["messages"].append({"role": "user", "content": user_msg})
        logging.info(f"USER: {user_msg}")

        try:
            # Invocamos el grafo manteniendo el estado acumulado
            state = await app.ainvoke(state)

            # Respuesta del asistente (saneada para UTF-8)
            response = state["messages"][-1]["content"]
            safe_response = response.encode("utf-8", errors="replace").decode("utf-8")

            print(f"ğŸ¤– {safe_response}\n")
            logging.info(f"ASSISTANT: {safe_response}")

        except Exception as e:
            print(f"âš ï¸ Error: {e}\n")
            logging.error(f"ERROR: {e}")

if __name__ == "__main__":
    asyncio.run(chat())
