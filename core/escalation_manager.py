# core/escalation_manager.py
import os
import time
import logging
from typing import Optional

import requests
from langchain_openai import ChatOpenAI

from core.notification import notify_encargado
from core.memory_manager import MemoryManager
from core.language_manager import language_manager

# ===============================================
# ESTADO Y CONFIGURACI√ìN GLOBAL
# ===============================================
pending_escalations: dict[str, dict] = {}

WHATSAPP_TOKEN = os.getenv("WHATSAPP_TOKEN")
WHATSAPP_PHONE_ID = os.getenv("WHATSAPP_PHONE_ID")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")

# Memoria para consolidar el contexto tras respuesta del encargado
_global_memory = MemoryManager(max_runtime_messages=8)


# ===============================================
# ENV√çO DE MENSAJES A WHATSAPP
# ===============================================
def send_whatsapp_text(user_id: str, text: str):
    """Env√≠a un mensaje de texto a WhatsApp usando la API Graph, con logs y control de errores."""
    if not WHATSAPP_TOKEN or not WHATSAPP_PHONE_ID:
        logging.error("‚ùå Falta WHATSAPP_TOKEN o WHATSAPP_PHONE_ID.")
        return

    # Sanea el n√∫mero de tel√©fono (solo d√≠gitos)
    phone = str(user_id).strip().replace("+", "").replace(" ", "")
    if not phone.isdigit():
        logging.warning(f"‚ö†Ô∏è ID no v√°lido para WhatsApp: {user_id}")
        return

    url = f"https://graph.facebook.com/v19.0/{WHATSAPP_PHONE_ID}/messages"
    headers = {
        "Authorization": f"Bearer {WHATSAPP_TOKEN}",
        "Content-Type": "application/json",
    }
    payload = {
        "messaging_product": "whatsapp",
        "to": phone,
        "type": "text",
        "text": {"body": text.strip()},
    }

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=15)
        if r.status_code == 200:
            logging.info(f"üì§ WhatsApp ‚Üí {phone}: {text[:80]}...")
        else:
            logging.error(f"‚ö†Ô∏è Fallo HTTP {r.status_code} enviando WhatsApp: {r.text}")
    except Exception as e:
        logging.error(f"‚ö†Ô∏è Error enviando WhatsApp: {e}", exc_info=True)


# ===============================================
# UTILIDADES DE IDIOMA
# ===============================================
def _extract_lang_from_history(conversation_id: str) -> Optional[str]:
    """Recupera [lang:xx] del historial persistente (cualquier role)."""
    try:
        history = _global_memory.get_context(conversation_id, limit=20)
        for msg in reversed(history):
            content = (msg or {}).get("content", "")
            if isinstance(content, str) and content.strip().startswith("[lang:") and content.strip().endswith("]"):
                inner = content.strip()[6:-1].lower()
                if len(inner) == 2:
                    return inner
        return None
    except Exception:
        return None


# ===============================================
# ESCALACI√ìN: MARCAR COMO PENDIENTE
# ===============================================
async def mark_pending(conversation_id: str, user_message: str):
    """Marca conversaci√≥n como pendiente, avisa al cliente y notifica al encargado."""
    now = time.time()
    existing = pending_escalations.get(conversation_id)

    # Evitar duplicados si ya se escal√≥ hace muy poco
    if existing and (now - existing.get("ts", 0)) < 15:
        logging.info(f"‚è≠Ô∏è Escalaci√≥n ya activa para {conversation_id}, evitando duplicados.")
        return

    pending_escalations[conversation_id] = {
        "question": user_message,
        "ts": now,
        "channel": "whatsapp",
    }

    # Idioma del cliente
    lang = _extract_lang_from_history(conversation_id) or language_manager.detect_language(user_message)

    # Persistir tag de idioma si no exist√≠a
    try:
        tag = f"[lang:{lang}]"
        history = _global_memory.get_context(conversation_id, limit=10)
        if not any(isinstance(m.get("content"), str) and m["content"].strip() == tag for m in history):
            _global_memory.save(conversation_id, "system", tag)
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è No se pudo guardar tag de idioma en mark_pending: {e}")

    # Aviso breve al cliente (traducido din√°micamente)
    base_meaning_es = "Un momento por favor, voy a consultarlo con el encargado."
    phrase = "üïì " + language_manager.short_phrase(base_meaning_es, lang)
    send_whatsapp_text(conversation_id, phrase)

    # Aviso al encargado (incluye idioma del cliente)
    lang_label = lang.upper()
    aviso = (
        f"üì© *Nueva consulta del cliente* (Idioma: {lang_label})\n"
        f"üÜî ID: `{conversation_id}`\n"
        f"‚ùì *Pregunta:* {user_message}\n\n"
        f"Responde con:\n"
        f"`RESPUESTA {conversation_id}: <tu respuesta>`"
    )
    await notify_encargado(aviso)


# ===============================================
# RESOLUCI√ìN DESDE EL ENCARGADO
# ===============================================
async def resolve_from_encargado(conversation_id: str, raw_text: str, hybrid_agent):
    """
    Reformula la respuesta del encargado y la env√≠a al cliente
    en el idioma del cliente. No menciona procesos internos.
    """
    logging.info(f"‚úâÔ∏è Resolviendo respuesta manual para {conversation_id}")

    original_user_message = pending_escalations.get(conversation_id, {}).get("question", "")

    # Idioma objetivo
    target_lang = _extract_lang_from_history(conversation_id) or language_manager.detect_language(
        original_user_message or raw_text
    )

    llm = ChatOpenAI(model=OPENAI_MODEL, temperature=0.2)

    system_prompt = (
        "Responde SIEMPRE en el MISMO idioma que el siguiente mensaje del cliente.\n"
        "Reformula el texto del encargado para el cliente con un tono c√°lido, claro y profesional.\n"
        "No menciones procesos internos, ni que proviene de un encargado, ni IA.\n"
        "S√© conciso (2‚Äì4 frases) y evita muletillas o cierres largos."
    )
    user_prompt = (
        f"Mensaje original del cliente (para detectar idioma):\n{original_user_message}\n\n"
        f"Respuesta del encargado (posiblemente en otro idioma):\n{raw_text}\n\n"
        "Devu√©lveme √∫nicamente el mensaje final para el cliente."
    )

    # Reformulaci√≥n con OpenAI
    try:
        reformulated = await llm.ainvoke([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ])
        final_text = reformulated.content.strip()
    except Exception as e:
        logging.error(f"‚ùå Error al reformular respuesta del encargado: {e}", exc_info=True)
        final_text = raw_text

    # Garantizar idioma final
    try:
        final_text = language_manager.ensure_language(final_text, target_lang)
    except Exception:
        pass

    # Guardar en memoria
    try:
        tag = f"[lang:{target_lang}]"
        hist = _global_memory.get_context(conversation_id, limit=10)
        if not any(isinstance(m.get("content"), str) and m["content"].strip() == tag for m in hist):
            _global_memory.save(conversation_id, "system", tag)
        _global_memory.save(conversation_id, "assistant", final_text)
        logging.info(f"üß† Memoria actualizada (encargado) para {conversation_id}: {final_text}")
    except Exception as e:
        logging.error(f"‚ö†Ô∏è No se pudo guardar en memoria: {e}")

    # Env√≠o al cliente por WhatsApp
    try:
        logging.info(f"üöÄ Enviando al cliente {conversation_id} por WhatsApp: {final_text}")
        send_whatsapp_text(conversation_id, final_text)
    except Exception as e:
        logging.error(f"üí• Error al enviar mensaje final al cliente: {e}", exc_info=True)

    # Limpiar estado y notificar cierre
    pending_escalations.pop(conversation_id, None)
    await notify_encargado(
        f"‚úÖ Respuesta enviada al cliente *{conversation_id}*.\n\nüßæ *Mensaje final:* {final_text}"
    )
